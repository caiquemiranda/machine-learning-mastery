{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seu primeiro projeto de aprendizado de máquina em Python passo a passo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você precisa ver como todas as peças de um projeto de aprendizado de máquina de modelagem preditiva realmente\n",
    "t juntos. Nesta lição, você concluirá seu primeiro projeto de aprendizado de máquina usando Python.\n",
    "Neste projeto de tutorial passo a passo, você irá:\n",
    "\n",
    ". Baixe e instale o Python SciPy e obtenha o pacote mais útil para aprendizado de máquina\n",
    "em Python.\n",
    ". Carregue um conjunto de dados e entenda sua estrutura usando resumos estatísticos e visualização de dados\n",
    "ização.\n",
    ". Crie 6 modelos de aprendizado de máquina, escolha o melhor e conquiste a confiança de que a precisão é\n",
    "confiável.\n",
    "\n",
    "Se você é um iniciante em aprendizado de máquina e quer finalmente começar a usar o Python, este\n",
    "tutorial foi projetado para você. Vamos começar!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O Hello World do aprendizado de máquina"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor pequeno projeto para começar em uma nova ferramenta é a classificação da íris\n",
    "flores. Isto é um\n",
    "bom conjunto de dados para seu primeiro projeto porque é muito bem compreendido.\n",
    "\n",
    ". Os atributos são numéricos, então você tem que descobrir como carregar e manipular os dados.\n",
    ". É um problema de classificação, permitindo que você pratique com um tipo mais fácil de supervisão\n",
    "algoritmo de aprendizagem.\n",
    ". É um problema de classificação multiclasse (multi-nominal) que pode requerer alguns\n",
    "manuseio.\n",
    ". Tem apenas 4 atributos e 150 linhas, o que significa que é pequeno e cabe facilmente na memória (e\n",
    "uma tela ou uma única folha de papel).\n",
    ". Todos os atributos numéricos estão nas mesmas unidades e na mesma escala, não exigindo qualquer\n",
    "dimensionamento ou transformações especiais para começar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial, vamos trabalhar em um pequeno projeto de aprendizado de máquina de ponta a ponta.\n",
    "Aqui está uma visão geral do que vamos cobrir:\n",
    "1. Carregando o conjunto de dados.\n",
    "2. Resumindo o conjunto de dados.\n",
    "3. Visualizando o conjunto de dados.\n",
    "4. Avaliação de alguns algoritmos.\n",
    "5. Fazendo algumas previsões.\n",
    "\n",
    "Não se apresse e trabalhe em cada etapa. Tente digitar os comandos você mesmo ou\n",
    "copie e cole os comandos para acelerar as coisas. Inicie seu ambiente interativo Python\n",
    "e vamos começar com seu projeto de aprendizado de máquina hello world em Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar os dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, vamos carregar as bibliotecas e o arquivo CSV de dados da íris da URL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importar bibliotecas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos importar todos os módulos, funções e objetos que usaremos neste tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo deve carregar sem erro. Se você tiver um erro, pare. Você precisa de um SciPy funcional\n",
    "ambiente antes de continuar. Veja o conselho no Capítulo 2 sobre como configurar seu ambiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregar conjunto de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados da íris pode ser baixado do repositório UCI Machine Learning1. Nós estamos usando\n",
    "Pandas para carregar os dados. Também usaremos o Pandas a seguir para explorar os dados com descrições estatísticas e visualização de dados. Observe que estamos especificando os nomes de cada coluna quando\n",
    "carregando os dados. Isso ajudará mais tarde, quando explorarmos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = 'iris.data.csv'\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(filename, names=names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumir o conjunto de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é hora de dar uma olhada nos dados. Nesta etapa, vamos dar uma olhada nos dados de um\n",
    "algumas maneiras diferentes:\n",
    "\n",
    ". Dimensões do conjunto de dados.\n",
    ". Peek nos próprios dados.\n",
    ". Resumo estatístico de todos os atributos.\n",
    ". Decomposição dos dados pela variável de classe.\n",
    "\n",
    "Não se preocupe, cada olhar para os dados é um comando. Estes são comandos úteis que você\n",
    "pode usar repetidamente em projetos futuros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimensões do conjunto de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ter uma ideia rápida de quantas instâncias (linhas) e quantos atributos (colunas) o\n",
    "data contém com a propriedade de forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Espreite os dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é sempre uma boa ideia observar seus dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resumo Estatístico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos dar uma olhada em um resumo de cada atributo. Isso inclui a contagem, média, o\n",
    "valores mínimos e máximos, bem como alguns percentis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions\n",
    "print(dataset.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribuição de classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora dar uma olhada no número de instâncias (linhas) que pertencem a cada classe. podemos ver\n",
    "isso como uma contagem absoluta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos uma ideia básica sobre os dados. Precisamos estender isso com algumas visualizações. Nós\n",
    "veremos dois tipos de gráficos:\n",
    "\n",
    ". Gráficos univariados para entender melhor cada atributo.\n",
    ". Gráficos multivariados para entender melhor as relações entre os atributos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gráficos univariados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começaremos com alguns gráficos univariados, ou seja, gráficos de cada variável individual. Dado que\n",
    "as variáveis de entrada são numéricas, podemos criar gráficos de caixa e bigode de cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que talvez duas das variáveis de entrada tenham uma distribuição gaussiana. Isso é útil\n",
    "observar como podemos usar algoritmos que podem explorar essa suposição."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gráficos Multivariados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos olhar para as interações entre as variáveis. Vejamos os gráficos de dispersão de todos\n",
    "pares de atributos. Isso pode ser útil para identificar relacionamentos estruturados entre variáveis de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "scatter_matrix(dataset)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe o agrupamento diagonal de alguns pares de atributos. Isso sugere uma alta correlação e\n",
    "uma relação previsível."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avalie alguns algoritmos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é hora de criar alguns modelos dos dados e estimar sua precisão em dados não vistos.\n",
    "Aqui está o que vamos cobrir nesta etapa:\n",
    "\n",
    "1. Separe um conjunto de dados de validação.\n",
    "2. Configure o equipamento de teste para usar a validação cruzada de 10 vezes.\n",
    "3. Construa 5 modelos diferentes para prever espécies de\n",
    "medições superiores\n",
    "4. Selecione o melhor modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criar um conjunto de dados de validação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos saber se o modelo que criamos é bom ou não. Mais tarde, usaremos\n",
    "métodos estatísticos para estimar a precisão dos modelos que criamos em dados não vistos.\n",
    "Também queremos uma estimativa mais concreta da precisão do melhor modelo em dados não vistos por\n",
    "avaliando-o em dados reais não vistos. Ou seja, vamos reter alguns dados que o\n",
    "algoritmos não conseguirão ver e usaremos esses dados para obter uma segunda e independente ideia de quão preciso o melhor modelo pode realmente ser. Vamos dividir o conjunto de dados carregado em dois, 80%\n",
    "dos quais usaremos para treinar nossos modelos e 20% que reteremos como um conjunto de dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n",
    "test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você tem dados de treinamento no treino_X e no treino_Y para preparar modelos e um\n",
    "Validação_X e conjuntos de validação_Y que podemos usar mais tarde."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Equipamento de teste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos validação cruzada de 10 vezes para estimar a precisão. Isso dividirá nosso conjunto de dados em 10\n",
    "partes, treine em 9 e teste em 1 e repita para todas as combinações de divisões de teste de trem. Nós estamos usando\n",
    "a métrica de precisão para avaliar modelos. Esta é uma razão entre o número de previsões corretas\n",
    "instâncias dividido pelo número total de instâncias no conjunto de dados multiplicado por 100 para fornecer um\n",
    "porcentagem (por exemplo, 95% de precisão). Estaremos usando a variável de pontuação quando executarmos build e\n",
    "avalie cada modelo a seguir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construir modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não sabemos quais algoritmos seriam bons para esse problema ou quais configurações usar.\n",
    "A partir dos gráficos, temos uma ideia de que algumas das classes são parcialmente separáveis linearmente em algumas\n",
    "dimensões, então esperamos resultados geralmente bons. Vamos avaliar seis algoritmos diferentes:\n",
    "\n",
    ". Regressão Logística (LR).\n",
    "\n",
    ". Análise Discriminante Linear (LDA).\n",
    "\n",
    ". k-vizinhos mais próximos (KNN).\n",
    "\n",
    ". Árvores de classificação e regressão (CART).\n",
    "\n",
    ". Gaussian Naive Bayes (NB).\n",
    "\n",
    ". Support Vector Machines (SVM).\n",
    "\n",
    "Esta lista é uma boa mistura de linear simples (LR e LDA), não linear (KNN, CART, NB\n",
    "e SVM). Redefinimos a semente do número aleatório antes de cada execução para garantir que o\n",
    "avaliação de cada algoritmo é realizada usando exatamente as mesmas divisões de dados. Ele garante o\n",
    "os resultados são diretamente comparáveis. Vamos construir e avaliar nossos cinco modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecione o melhor modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos 6 modelos e estimativas de precisão para cada um. Precisamos comparar os modelos para\n",
    "uns aos outros e selecione o mais preciso. Executando o exemplo acima, obtemos o seguinte raw\n",
    "resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REsul"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos 6 modelos e estimativas de precisão para cada um. Precisamos comparar os modelos para\n",
    "uns aos outros e selecione o mais preciso. Executando o exemplo acima, obtemos o seguinte raw\n",
    "resultados: Podemos ver que parece que KNN tem a maior pontuação de precisão estimada. Nós também podemos\n",
    "crie um gráfico dos resultados da avaliação do modelo e compare a dispersão e a precisão média\n",
    "de cada modelo. Existe uma população de medidas de precisão para cada algoritmo porque cada\n",
    "algoritmo foi avaliado 10 vezes (validação cruzada de 10 vezes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver que os gráficos de caixa e bigode são compactados no topo do intervalo, com muitos\n",
    "amostras alcançando 100% de precisão."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fazer previsões"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo KNN foi o modelo mais preciso que testamos. Agora queremos ter uma ideia\n",
    "da precisão do modelo em nosso conjunto de dados de validação. Isso nos dará um nal independente\n",
    "verificar a precisão do melhor modelo. É importante manter um conjunto de validação para o caso\n",
    "você cometeu um deslize durante o treinamento, como uma sobreposição ao conjunto de treinamento ou um vazamento de dados. Ambos\n",
    "resultará em um resultado excessivamente otimista. Podemos executar o modelo KNN diretamente na validação\n",
    "defina e resuma os resultados como uma pontuação final de precisão, uma matriz de confusão e uma classificação\n",
    "relatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a precisão é de 0,9 ou 90%. A matriz de confusão fornece uma indicação de\n",
    "os três erros cometidos. Finalmente, o relatório de classificação fornece uma divisão de cada classe por precisão, recall, pontuação f1 e suporte mostrando excelentes resultados (concedido o conjunto de dados de validação\n",
    "Era pequeno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
