{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos de classificação de verificação pontual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A verificação pontual é uma maneira de descobrir quais algoritmos funcionam bem em seu aprendizado de máquina problema. Você não pode saber quais algoritmos são mais adequados para o seu problema de antemão. Você deve experimentar uma série de métodos e focar a atenção naqueles que provam ser os mais promissor. Neste capítulo, você descobrirá seis algoritmos de aprendizado de máquina que você pode usar ao verificar seu problema de classificação em Python com o scikit-learn. \n",
    "\n",
    "1. Como verificar algoritmos de aprendizado de máquina em um problema de classificação.\n",
    "2. Como verificar dois algoritmos de classificação linear.\n",
    "3. Como verificar quatro algoritmos de classificação não linear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação imediata do algoritmo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você não pode saber qual algoritmo funcionará melhor em seu conjunto de dados de antemão. Você deve usar tentativa e erro para descobrir uma lista de algoritmos que funcionam bem em seu problema que você pode em seguida, dobre e sintonize ainda mais. Eu chamo esse processo de verificação pontual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questão não é: qual algoritmo devo usar em meu conjunto de dados? Em vez disso, é: O que algoritmos devo verificar no meu conjunto de dados? Você pode adivinhar o que os algoritmos podem fazer bem em seu conjunto de dados, e isso pode ser um bom ponto de partida. Eu recomendo tentar uma mistura de algoritmos e veja o que é bom para escolher a estrutura em seus dados. Abaixo estão alguns sugestões ao verificar algoritmos no seu conjunto de dados:\n",
    "\n",
    "* Tente uma mistura de representações de algoritmos (por exemplo, instâncias e árvores).\n",
    "* Tente uma mistura de algoritmos de aprendizado (por exemplo, algoritmos diferentes para aprender o mesmo tipo de representação). Tente uma mistura de tipos de modelagem (por exemplo, funções lineares e não lineares ou funções paramétricas e não paramétrico).\n",
    "* Vamos ser específicos. Na próxima seção, veremos algoritmos que você pode usar para verificar seu próximo projeto de aprendizado de máquina de classificação em Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visão geral dos algoritmos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em seis algoritmos de classificação que você pode verificar no seu conjunto de dados. Começando com dois algoritmos de aprendizado de máquina linear:\n",
    "\n",
    "* Regressão Logística.\n",
    "* Análise Discriminante Linear.\n",
    "\n",
    "Em seguida, analisando quatro algoritmos de aprendizado de máquina não lineares:\n",
    "\n",
    "* k-vizinhos mais próximos.\n",
    "* Naive Bayes.\n",
    "* Árvores de classificação e regressão.\n",
    "* Máquinas de vetores de suporte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada receita é demonstrada no conjunto de dados de diabetes dos índios Pima. Um arnês de teste usando validação cruzada de 10 vezes é usado para demonstrar como verificar cada aprendizado de máquina algoritmo e medidas de precisão média são usadas para indicar o desempenho do algoritmo. as receitas suponha que você conheça cada algoritmo de aprendizado de máquina e como usá-los. Vamos não entrar na API ou parametrização de cada algoritmo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos de aprendizado de máquina linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seção demonstra receitas mínimas de como usar dois algoritmos lineares de aprendizado de máquina: regressão logística e análise discriminante linear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regressão Logística"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão logística assume uma distribuição gaussiana para as variáveis de entrada numérica e pode modelar problemas de classificação binária. Você pode construir um modelo de regressão logística usando o Classe de regressão logística1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filename = 'datasets/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres',\n",
    "         'skin', 'test', 'mass', \n",
    "         'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise Discriminante Linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise Discriminante Linear ou LDA é uma técnica estatística para binário e multiclasse classi cação. Ele também assume uma distribuição gaussiana para as variáveis de entrada numérica. Você pode construa um modelo LDA usando a classe LinearDiscriminantAnalysis2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\GIT-repository\\github-machine-learning-mastery\\machine-learning-mastery\\10-Algoritmos_de_classificação_de_verificação_pontual.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-machine-learning-mastery/machine-learning-mastery/10-Algoritmos_de_classifica%C3%A7%C3%A3o_de_verifica%C3%A7%C3%A3o_pontual.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m Y \u001b[39m=\u001b[39m array[:,\u001b[39m8\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-machine-learning-mastery/machine-learning-mastery/10-Algoritmos_de_classifica%C3%A7%C3%A3o_de_verifica%C3%A7%C3%A3o_pontual.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m num_folds \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-machine-learning-mastery/machine-learning-mastery/10-Algoritmos_de_classifica%C3%A7%C3%A3o_de_verifica%C3%A7%C3%A3o_pontual.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-machine-learning-mastery/machine-learning-mastery/10-Algoritmos_de_classifica%C3%A7%C3%A3o_de_verifica%C3%A7%C3%A3o_pontual.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m LinearDiscriminantAnalysis()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-machine-learning-mastery/machine-learning-mastery/10-Algoritmos_de_classifica%C3%A7%C3%A3o_de_verifica%C3%A7%C3%A3o_pontual.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m results \u001b[39m=\u001b[39m cross_val_score(model, X, Y, cv\u001b[39m=\u001b[39mkfold)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m*\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 435\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(n_splits\u001b[39m=\u001b[39;49mn_splits, shuffle\u001b[39m=\u001b[39;49mshuffle, random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mshuffle must be True or False; got \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shuffle))\n\u001b[0;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shuffle \u001b[39mand\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# None is the default\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSetting a random_state has no effect since shuffle is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFalse. You should leave \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrandom_state to its default (None), or set shuffle=True.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m=\u001b[39m n_splits\n\u001b[0;32m    303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshuffle \u001b[39m=\u001b[39m shuffle\n",
      "\u001b[1;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "# LDA Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filename = 'datasets/diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres',\n",
    "         'skin', 'test', 'mass', \n",
    "         'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos de aprendizado de máquina não linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seção demonstra receitas mínimas de como usar 4 algoritmos de aprendizado de máquina não linear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### k-vizinhos mais próximos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo k-Nearest Neighbors (ou KNN) usa uma métrica de distância para encontrar os k mais semelhantes instâncias nos dados de treinamento para uma nova instância e leva o resultado médio dos vizinhos como a previsão. Você pode construir um modelo KNN usando o KNeighborsClassifier class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes calcula a probabilidade de cada classe e a probabilidade condicional de cada classe dado cada valor de entrada. Essas probabilidades são estimadas para novos dados e multiplicadas, assumindo que eles são todos independentes (uma suposição simples ou ingênua). Ao trabalhar com dados de valor real, assume-se que uma distribuição gaussiana estima facilmente as probabilidades de variáveis de entrada usando a Função de Densidade de Probabilidade Gaussiana. Você pode construir um ingênuo Modelo de Bayes usando o GaussianNB class4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Árvores de classificação e regressão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árvores de classificação e regressão (CART ou apenas árvores de decisão) constroem uma árvore binária a partir os dados de treinamento. Os pontos de divisão são escolhidos avidamente avaliando cada atributo e cada valor de cada atributo nos dados de treinamento para minimizar uma função de custo (como o índice de Gini). Você pode construir um modelo CART usando a classe DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Máquinas de vetores de suporte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (ou SVM) buscam uma linha que melhor separe duas classes. Esses dados instâncias que estão mais próximas da linha que melhor separa as classes são chamadas de vetores de suporte e em uência onde a linha é colocada. O SVM foi estendido para oferecer suporte a várias classes. De particular importância é o uso de diferentes funções do kernel por meio do parâmetro do kernel. Uma poderosa função de base radial é usada por padrão. Você pode construir um modelo SVM usando o Classe SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
