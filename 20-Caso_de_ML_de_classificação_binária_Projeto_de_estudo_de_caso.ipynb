{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado de máquina de classificação binária Projeto de estudo de caso"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você trabalha com um problema de aprendizado de máquina de modelagem preditiva de ponta a ponta? Nisso\n",
    "lição você trabalhará com um problema de modelagem preditiva de classificação de estudo de caso em Python\n",
    "incluindo cada etapa do processo de aprendizado de máquina aplicado. Depois de concluir este projeto, você\n",
    "saberá:\n",
    "\n",
    ". Como trabalhar com um problema de modelagem preditiva de classificação de ponta a ponta.\n",
    ". Como usar transformações de dados para melhorar o desempenho do modelo.\n",
    ". Como usar o ajuste de algoritmo para melhorar o desempenho do modelo.\n",
    ". Como usar métodos de conjunto e ajuste de métodos de conjunto para melhorar o desempenho do modelo\n",
    "mance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição do Problema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O foco deste projeto será o conjunto de dados Sonar Mines vs Rocks1. O problema é prever\n",
    "objetos de metal ou rocha dos dados de retorno do sonar. Cada padrão é um conjunto de 60 números no intervalo\n",
    "0,0 a 1,0. Cada número representa a energia dentro de uma determinada banda de frequência, integrada\n",
    "durante um determinado período de tempo. O rótulo associado a cada registro contém a letra R se\n",
    "o objeto é uma rocha e M se for uma mina (cilindro de metal). Os números nas etiquetas estão em\n",
    "ordem crescente do ângulo de aspecto, mas eles não codificam o ângulo diretamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar o conjunto de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar carregando as bibliotecas necessárias para este projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode baixar o conjunto de dados do site do repositório UCI Machine Learning2 e salvar\n",
    "no diretório de trabalho local com o nome de arquivo sonar.all-data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = 'sonar.all-data.csv'\n",
    "dataset = read_csv(url, header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver que não estamos especificando os nomes dos atributos desta vez. Isto é porque\n",
    "além do atributo de classe (a última coluna), as variáveis não possuem nomes significativos.\n",
    "Também indicamos que não há informações de cabeçalho, isso é para evitar que o código de carregamento do arquivo leve o\n",
    "primeiro registro como os nomes das colunas. Agora que carregamos o conjunto de dados, podemos dar uma olhada nele."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisar dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em nossos dados carregados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estatísticas descritivas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começaremos confirmando as dimensões do conjunto de dados, por ex. o número de linhas e\n",
    "colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 208 instâncias para trabalhar e podemos confirmar que os dados têm 61 atributos, incluindo\n",
    "o atributo de classe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos também os tipos de dados de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "set_option('display.max_rows', 500)\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todos os atributos são numéricos (aveia) e que o valor da classe foi\n",
    "lido como um objeto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora dar uma olhada nas primeiras 20 linhas dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "set_option('display.width', 100)\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso não mostra todas as colunas, mas podemos ver que todos os dados têm a mesma escala. Nós\n",
    "também pode ver que o atributo de classe (60) tem valores de string."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos resumir a distribuição de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions, change precision to 3 places\n",
    "set_option('precision', 3)\n",
    "print(dataset.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, como esperamos, os dados têm o mesmo intervalo, mas valores médios curiosamente diferentes.\n",
    "Pode haver algum benefício em padronizar os dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada rápida na divisão dos valores de classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby(60).size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que as classes estão razoavelmente equilibradas entre M (minas) e R (rochas)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizações de dados unimodais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos as visualizações de atributos individuais. Muitas vezes é útil olhar para os seus dados\n",
    "usando várias visualizações diferentes para gerar ideias. Vejamos os histogramas de cada\n",
    "atributo para obter uma noção das distribuições de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que há muitas distribuições gaussianas e talvez algumas exponenciais.\n",
    "como distribuições para outros atributos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada na mesma perspectiva dos dados usando gráficos de densidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density\n",
    "dataset.plot(kind='density', subplots=True, layout=(8,8), sharex=False, legend=False,\n",
    "fontsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é útil, você pode ver que muitos dos atributos têm uma distribuição distorcida. Um poder\n",
    "transformar como uma transformação Box-Cox que pode corrigir a distorção nas distribuições pode ser\n",
    "útil."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É sempre bom olhar para gráficos de caixa e bigodes de atributos numéricos para ter uma ideia de\n",
    "a propagação de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(8,8), sharex=False, sharey=False,\n",
    "fontsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os atributos têm spreads bastante diferentes. Como as escalas são iguais,\n",
    "pode sugerir algum benefício em padronizar os dados para modelagem para obter todas as médias alinhadas\n",
    "acima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizações de dados multimodais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar as correlações entre os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que também há alguma estrutura na ordem dos atributos. O vermelho ao redor\n",
    "a diagonal sugere que os atributos que estão próximos uns dos outros são geralmente mais correlacionados\n",
    "um com o outro. As manchas azuis também sugerem alguma correlação negativa moderada quanto mais\n",
    "os atributos estão distantes um do outro na ordenação. Isso faz sentido se a ordem do\n",
    "Os atributos referem-se ao ângulo dos sensores para o chirp do sonar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de dados de validação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma boa ideia usar um conjunto de validação. Esta é uma amostra dos dados que mantemos\n",
    "de volta de nossa análise e modelagem. Nós o usamos logo no final do nosso projeto para con rmar o\n",
    "precisão do nosso modelo nal. É um teste de fumaça que podemos usar para ver se erramos e\n",
    "nos dê confiança em nossas estimativas de precisão em dados não vistos. Usaremos 80% do conjunto de dados\n",
    "para modelagem e reter 20% para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:60].astype(float)\n",
    "Y = array[:,60]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n",
    "test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar algoritmos: linha de base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não sabemos quais algoritmos se sairão bem neste conjunto de dados. A intuição sugere com base na distância\n",
    "algoritmos como k-Nearest Neighbors e Support Vector Machines podem funcionar bem. vamos projetar\n",
    "nosso arnês de teste. Usaremos validação cruzada de 10 vezes. O conjunto de dados não é muito pequeno e isso é\n",
    "uma boa configuração de chicote de teste padrão. Avaliaremos algoritmos usando a precisão\n",
    "métrica. Esta é uma métrica bruta que dará uma ideia rápida de quão correto é um determinado modelo. Mais\n",
    "útil em problemas de classificação binária como este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma linha de base de desempenho neste problema e verificar no local uma série de diferentes\n",
    "algoritmos. Vamos selecionar um conjunto de diferentes algoritmos capazes de trabalhar nesta classificação\n",
    "problema. Os seis algoritmos selecionados incluem:\n",
    "\n",
    ". Algoritmos Lineares: Regressão Logística (LR) e Análise Discriminante Linear (LDA).\n",
    ". Algoritmos Não Lineares: Árvores de Classificação e Regressão (CART), Vetor de Suporte\n",
    "Machines (SVM), Gaussian Naive Bayes (NB) e k-Nearest Neighbors (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os algoritmos usam parâmetros de ajuste padrão. Vamos comparar os algoritmos. Vamos\n",
    "exibir a média e o desvio padrão de precisão para cada algoritmo à medida que o calculamos e\n",
    "coletar os resultados para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do exemplo fornece a saída abaixo. Os resultados sugerem que tanto a Logística\n",
    "A regressão e os k-vizinhos mais próximos podem valer a pena um estudo mais aprofundado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estes são apenas valores médios de precisão. É sempre bom olhar para a distribuição de precisão\n",
    "valores calculados em dobras de validação cruzada. Podemos fazer isso graficamente usando caixa e bigode\n",
    "parcelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados mostram uma distribuição apertada para KNN que é encorajadora, sugerindo baixa variância.\n",
    "Os maus resultados para SVM são surpreendentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível que a distribuição variada dos atributos esteja afetando a precisão\n",
    "de algoritmos como o SVM. Na próxima seção, repetiremos essa verificação aleatória com um\n",
    "cópia do conjunto de dados de treinamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar algoritmos: padronizar dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspeitamos que as diferentes distribuições dos dados brutos possam estar afetando negativamente a habilidade\n",
    "de alguns dos algoritmos. Vamos avaliar os mesmos algoritmos com uma cópia padronizada do\n",
    "conjunto de dados. É aqui que os dados são transformados de forma que cada atributo tenha um valor médio de zero\n",
    "e um desvio padrão de um. Também precisamos evitar vazamento de dados quando transformamos o\n",
    "dados. Uma boa forma de evitar vazamentos é usar pipelines que padronizam os dados e constroem o\n",
    "modelo para cada dobra no chicote de teste de validação cruzada. Dessa forma, podemos obter uma estimativa justa\n",
    "de como cada modelo com dados padronizados pode funcionar em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',\n",
    "LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA',\n",
    "LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
    "KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
    "DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n",
    "GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do exemplo fornece os resultados listados abaixo. Podemos ver que KNN ainda está fazendo\n",
    "bem, ainda melhor do que antes. Também podemos ver que a padronização dos dados elevou\n",
    "a habilidade de SVM para ser o algoritmo mais preciso testado até agora."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, devemos traçar a distribuição das pontuações de precisão usando gráficos de caixa e bigode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados sugerem aprofundar os algoritmos SVM e KNN. É muito provável que\n",
    "a configuração além do padrão pode render modelos ainda mais precisos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajuste de Algoritmo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, investigamos o ajuste dos parâmetros para dois algoritmos que se mostram promissores de\n",
    "a verificação pontual na seção anterior: KNN e SVM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos começar ajustando o número de vizinhos para KNN. O número padrão de vizinhos\n",
    "é 7. Abaixo, tentamos todos os valores ímpares de k de 1 a 21, cobrindo o valor padrão de 7. Cada valor de k\n",
    "é avaliado usando validação cruzada de 10 vezes no conjunto de dados padronizado de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled KNN\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos imprimir a configuração que resultou na maior precisão, bem como a precisão\n",
    "de todos os valores experimentados. Executando o exemplo, vemos os resultados abaixo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a configuração ótima é K=1. Isso é interessante, pois o algoritmo\n",
    "faça previsões usando a instância mais semelhante apenas no conjunto de dados de treinamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ajustar dois parâmetros-chave do algoritmo SVM, o valor de C (quanto relaxar o\n",
    "margin) e o tipo de kernel. O padrão para SVM (a classe SVC) é usar o Radial\n",
    "Kernel de função de base (RBF) com um valor C definido como 1,0. Como com KNN, vamos realizar uma grade\n",
    "pesquisa usando validação cruzada de 10 vezes com uma cópia padronizada do conjunto de dados de treinamento. Vamos\n",
    "tente vários tipos de kernel mais simples e valores C com menos viés e mais viés (menor que e\n",
    "mais de 1,0 respectivamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled SVM\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do exemplo imprime a melhor configuração, a precisão, bem como as precisões\n",
    "para todas as combinações de configuração."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a configuração mais precisa foi SVM com um kernel RBF e um valor C\n",
    "de 1,5. A precisão de 86,7470% é aparentemente melhor do que a KNN poderia alcançar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de conjunto( Ensemble )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra maneira de melhorar o desempenho dos algoritmos nesse problema é usando\n",
    "métodos de conjunto. Nesta seção, avaliaremos quatro métodos diferentes de aprendizado de máquina ensemble\n",
    "algoritmos, dois métodos boosting e dois bagging:\n",
    "\n",
    ". Métodos de Boosting: AdaBoost (AB) e Gradient Boosting (GBM).\n",
    ". Métodos de ensacamento: Random Forests (RF) e Extra Trees (ET).\n",
    "\n",
    "Usaremos o mesmo equipamento de teste de antes, validação cruzada de 10 vezes. Sem padronização de dados\n",
    "é usado neste caso porque todos os quatro algoritmos de conjunto são baseados em árvores de decisão que são\n",
    "menos sensível a distribuições de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "ensembles.append(('RF', RandomForestClassifier()))\n",
    "ensembles.append(('ET', ExtraTreesClassifier()))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ambas as técnicas de aumento fornecem fortes pontuações de precisão na casa dos 80 (%)\n",
    "com configurações padrão. Podemos plotar a distribuição de pontuações de precisão na cruz\n",
    "dobras de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados sugerem que o GBM pode ser digno de um estudo mais aprofundado, com uma média forte e um spread\n",
    "que se inclina para altos 90s (%) em precisão."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizar modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O SVM se mostrou mais promissor como um modelo estável e de baixa complexidade para este problema. Em\n",
    "Nesta seção, vamos finalizar o modelo treinando-o em todo o conjunto de dados de treinamento e fazer\n",
    "previsões para o conjunto de dados de validação de espera para confirmar nossas conclusões. Uma parte dos resultados foi\n",
    "que o SVM tem melhor desempenho quando o conjunto de dados é padronizado para que todos os atributos tenham uma média\n",
    "valor de zero e um desvio padrão de um. Podemos calcular isso a partir de todo o treinamento\n",
    "conjunto de dados e aplique a mesma transformação aos atributos de entrada do conjunto de dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=1.5)\n",
    "model.fit(rescaledX, Y_train)\n",
    "# estimate accuracy on validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que alcançamos uma precisão de quase 86% no conjunto de dados de validação retido. A\n",
    "pontuação que se aproxima de nossas expectativas estimadas acima durante o ajuste do SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
