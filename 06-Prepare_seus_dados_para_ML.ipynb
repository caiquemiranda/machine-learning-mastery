{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare seus dados para aprendizado de máquina"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitos algoritmos de aprendizado de máquina fazem suposições sobre seus dados. Muitas vezes é muito bom\n",
    "idéia de preparar seus dados de forma a melhor expor a estrutura do problema para a máquina\n",
    "algoritmos de aprendizado que você pretende usar. Neste capítulo, você descobrirá como preparar\n",
    "seus dados para aprendizado de máquina em Python usando o scikit-learn. Depois de concluir esta lição, você\n",
    "saberá como:\n",
    "1. Redimensione os dados.\n",
    "2. Padronize os dados.\n",
    "3. Normalize os dados.\n",
    "4. Binarize os dados.\n",
    "Vamos começar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need For Data Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você quase sempre precisa pré-processar seus dados. É uma etapa necessária. Uma dificuldade é que\n",
    "algoritmos diferentes fazem suposições diferentes sobre seus dados e podem exigir\n",
    "transforma. Além disso, quando você segue todas as regras e prepara seus dados, às vezes os algoritmos\n",
    "pode fornecer melhores resultados sem pré-processamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geralmente, eu recomendaria criar muitas exibições e transformações diferentes de seus dados,\n",
    "em seguida, exercite alguns algoritmos em cada exibição de seu conjunto de dados. Isso irá ajudá-lo a\n",
    "ush\n",
    "descubra quais transformações de dados podem ser melhores para expor a estrutura do seu problema em geral."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta lição, você trabalhará com 4 receitas diferentes de pré-processamento de dados para aprendizado de máquina.\n",
    "O conjunto de dados de diabetes Pima Indian é usado em cada receita. Cada receita segue a mesma estrutura:\n",
    "Carregue o conjunto de dados de um URL.\n",
    "Divida o conjunto de dados nas variáveis de entrada e saída para aprendizado de máquina.\n",
    "Aplique uma transformação de pré-processamento às variáveis de entrada.\n",
    "Resumir os dados para mostrar a alteração."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca scikit-learn fornece dois idiomas padrão para transformar dados. cada um é útil\n",
    "em diferentes circunstâncias. As transformações são calculadas de forma que possam ser aplicadas\n",
    "aos seus dados de treinamento e quaisquer amostras de dados que você possa ter no futuro. O scikit-learn\n",
    "A documentação contém algumas informações sobre como usar vários métodos diferentes de pré-processamento:\n",
    "Ajuste e transformação múltipla.\n",
    "Ajuste e transformação combinados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método Fit and Multiple Transform é a abordagem preferida. Você chama o fit()\n",
    "função para preparar os parâmetros da transformação uma vez em seus dados. Então mais tarde você pode usar\n",
    "a função transform() nos mesmos dados para prepará-los para modelagem e novamente no teste ou\n",
    "conjunto de dados de validação ou novos dados que você pode ver no futuro. A combinação de ajuste e transformação\n",
    "é uma conveniência que você pode usar para uma ou outras tarefas. Isso pode ser útil se você estiver interessado\n",
    "em plotar ou resumir os dados transformados. Você pode revisar a API de pré-processamento em\n",
    "scikit-learn aqui1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redimensionar dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando seus dados são compostos de atributos com escalas variadas, muitos algoritmos de aprendizado de máquina\n",
    "pode se beneficiar do redimensionamento dos atributos para que todos tenham a mesma escala. Muitas vezes isso é referido\n",
    "como normalização e atributos são frequentemente redimensionados no intervalo entre 0 e 1. Isso é\n",
    "útil para algoritmos de otimização usados no núcleo de algoritmos de aprendizado de máquina como gradiente\n",
    "descida. Também é útil para algoritmos que ponderam entradas como regressão e redes neurais\n",
    "e algoritmos que usam medidas de distância como k-Nearest Neighbors. Você pode redimensionar seus dados\n",
    "usando scikit-learn usando o MinMaxScaler class2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data (between 0 and 1)\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padronizar dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A padronização é uma técnica útil para transformar atributos com uma distribuição Gaussiana e\n",
    "médias diferentes e desvios padrão para uma distribuição Gaussiana padrão com uma média de\n",
    "0 e um desvio padrão de 1. É mais adequado para técnicas que assumem uma Gaussiana\n",
    "distribuição nas variáveis de entrada e funcionam melhor com dados reescalonados, como regressão linear,\n",
    "regressão logística e análise linear discriminada. Você pode padronizar dados usando o scikit-learn\n",
    "com a classe StandardScaler3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizar Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normalização no scikit-learn refere-se ao redimensionamento de cada observação (linha) para ter um comprimento de 1 (chamado\n",
    "uma norma unitária ou um vetor com o comprimento de 1 em álgebra linear). Este método de pré-processamento\n",
    "pode ser útil para conjuntos de dados esparsos (muitos zeros) com atributos de escalas variadas ao usar\n",
    "algoritmos que ponderam valores de entrada, como redes neurais e algoritmos que usam distância\n",
    "medidas como k-vizinhos mais próximos. Você pode normalizar dados em Python com scikit-learn\n",
    "usando o normalizador class4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarizar Dados (Tornar Binário)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode transformar seus dados usando um limite binário. Todos os valores acima do limite são\n",
    "marcados como 1 e todos iguais ou abaixo são marcados como 0. Isso é chamado de binarização de seus dados ou\n",
    "limitando seus dados. Pode ser útil quando você tem probabilidades de querer fazer nítidos\n",
    "valores. Também é útil na engenharia de recursos e você deseja adicionar novos recursos que indicam\n",
    "algo significativo. Você pode criar novos atributos binários em Python usando scikit-learn com\n",
    "a classe binarizador5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
