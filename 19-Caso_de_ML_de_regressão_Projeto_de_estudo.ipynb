{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de aprendizado de máquina de regressão Projeto de estudo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você trabalha com um problema de aprendizado de máquina de modelagem preditiva de ponta a ponta? Nisso\n",
    "lição você trabalhará através de um problema de modelagem preditiva de regressão de estudo de caso em Python\n",
    "incluindo cada etapa do processo de aprendizado de máquina aplicado. Depois de concluir este projeto, você\n",
    "saberá:\n",
    "\n",
    ". Como trabalhar com um problema de modelagem preditiva de regressão de ponta a ponta.\n",
    "\n",
    ". Como usar transformações de dados para melhorar o desempenho do modelo.\n",
    "\n",
    ". Como usar o ajuste de algoritmo para melhorar o desempenho do modelo.\n",
    "\n",
    ". Como usar métodos de conjunto e ajuste de métodos de conjunto para melhorar o desempenho do modelo\n",
    "mance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição do Problema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este projeto, investigaremos o conjunto de dados Boston House Price. Cada registro no banco de dados\n",
    "descreve um subúrbio ou cidade de Boston. Os dados foram extraídos do Boston Standard Metropolitan\n",
    "Área Estatística (SMSA) em 1970. Os atributos são de nidos da seguinte forma (retirados do UCI\n",
    "Repositório de aprendizado de máquina1):\n",
    "\n",
    "1. CRIM: taxa de criminalidade per capita por cidade\n",
    "2. ZN: proporção de terreno residencial zoneada para lotes acima de 25.000 m2.\n",
    "3. INDUS: proporção de hectares de negócios não varejistas por cidade\n",
    "4. CHAS: Variável fictícia Charles River (= 1 se o trecho limita o rio; 0 caso contrário)\n",
    "5. NOX: concentração de óxidos nítricos (partes por 10 milhões)\n",
    "6. 6. RM: número médio de divisões por habitação\n",
    "7. IDADE: proporção de unidades próprias construídas antes de 1940\n",
    "8. DIS: distâncias ponderadas para cinco centros de emprego de Boston\n",
    "9. RAD: índice de acessibilidade às rodovias radiais\n",
    "10. IMPOSTO: valor total do imposto predial por US$ 10.000\n",
    "11. PTRATIO: proporção aluno-professor por município\n",
    "12. B: 1000(Bk 􀀀 0:63)2 onde Bk é a proporção de negros por cidade\n",
    "13. LSTAT: % de status inferior da população\n",
    "14. MEDV: Valor médio de residências ocupadas pelos proprietários em US$ 1.000\n",
    "Podemos ver que os atributos de entrada possuem uma mistura de unidades."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar carregando as bibliotecas necessárias para este projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy\n",
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos carregar o conjunto de dados que você pode baixar do UCI Machine Learning\n",
    "site do repositório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataset = read_csv(filename, delim_whitespace=True, names=names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver que estamos especificando os nomes curtos para cada atributo para que possamos fazer referência\n",
    "eles claramente mais tarde. Você também pode ver que os atributos são delimitados por espaços em branco em vez de\n",
    "vírgulas neste arquivo e indicamos isso para ler a função csv () por meio do espaço em branco delim\n",
    "argumento. Agora temos nossos dados carregados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisar dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos dar uma olhada mais de perto em nossos dados carregados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estatísticas descritivas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar confirmando as dimensões do conjunto de dados, por exemplo o número de linhas e colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 506 instâncias para trabalhar e podemos confirmar que os dados têm 14 atributos, incluindo\n",
    "o atributo de saída MEDV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos também os tipos de dados de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todos os atributos são numéricos, principalmente valores reais (\n",
    "aveia) e alguns têm\n",
    "interpretado como inteiros (int)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora dar uma olhada nas primeiras 20 linhas dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos confirmar que as escalas para os atributos estão em todo lugar por causa da diferença\n",
    "unidades. Podemos nos beneficiar de algumas transformações mais tarde."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos resumir a distribuição de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions\n",
    "set_option('precision', 1)\n",
    "print(dataset.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos uma ideia melhor de quão diferentes são os atributos. Os valores mínimo e máximo\n",
    "também são os meios variam muito. Provavelmente obteremos melhores resultados redimensionando os dados\n",
    "de algum modo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos dar uma olhada na correlação entre todos os atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "set_option('precision', 2)\n",
    "print(dataset.corr(method='pearson'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto é interessante. Podemos ver que muitos dos atributos têm uma forte correlação (por exemplo, > 0,70 ou < -0,70). Por exemplo:\n",
    "\n",
    ". NOX e INDUS com 0,77.\n",
    ". DIS e INDUS com -0,71.\n",
    ". IMPOSTO e INDUS com 0,72.\n",
    ". IDADE e NOX com 0,73.\n",
    ". DIS e NOX com -0,78.\n",
    "\n",
    "Também parece que LSTAT tem uma boa correlação negativa com a variável de saída MEDV com\n",
    "um valor de -0,74."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizações de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizações de dados unimodais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos as visualizações de atributos individuais. Muitas vezes é útil olhar para os seus dados\n",
    "usando várias visualizações diferentes para gerar ideias. Vejamos os histogramas de cada\n",
    "atributo para obter uma noção das distribuições de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que alguns atributos podem ter uma distribuição exponencial, como CRIM, ZN,\n",
    "AGE e B. Podemos ver que outros podem ter uma distribuição bimodal como RAD e TAX."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos as mesmas distribuições usando gráficos de densidade que as suavizam um pouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density\n",
    "dataset.plot(kind='density', subplots=True, layout=(4,4), sharex=False, legend=False,\n",
    "fontsize=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso talvez acrescente mais evidências à nossa suspeita sobre possível exponencial e bimodal\n",
    "distribuições. Também parece que NOX, RM e LSTAT podem ser distribuições gaussianas distorcidas, que\n",
    "pode ser útil mais tarde com transformações."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos os dados com gráficos de caixa e bigodes de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False,\n",
    "fontsize=8)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso ajuda a apontar a distorção em muitas distribuições tanto que os dados parecem discrepantes\n",
    "(por exemplo, além do bigode das parcelas)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizações de dados multimodais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos algumas visualizações das interações entre variáveis. O melhor lugar para começar\n",
    "é uma matriz de gráfico de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "scatter_matrix(dataset)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que alguns dos atributos correlacionados mais altos mostram uma boa estrutura em seus\n",
    "relação. Não linear, mas boas relações curvas previsíveis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também visualizar as correlações entre os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,14,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cor vermelha escura mostra correlação positiva, enquanto a cor azul escura mostra correlação negativa\n",
    "correlação. Também podemos ver alguns vermelhos escuros e azuis escuros que sugerem candidatos para remoção\n",
    "para melhorar a precisão dos modelos posteriormente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumo das Ideias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há muita estrutura neste conjunto de dados. Precisamos pensar em transformações que poderíamos usar\n",
    "posteriormente para expor melhor a estrutura que, por sua vez, pode melhorar a precisão da modelagem. até agora\n",
    "valeria a pena tentar:\n",
    "\n",
    ". Seleção de recursos e remoção dos atributos mais correlacionados.\n",
    ". Normalizando o conjunto de dados para reduzir o efeito de escalas diferentes.\n",
    ". Padronizar o conjunto de dados para reduzir os efeitos de diferentes distribuições.\n",
    "\n",
    "Com muito tempo adicional, eu também exploraria a possibilidade de binning (discretização)\n",
    "dos dados. Isso geralmente pode melhorar a precisão dos algoritmos de árvore de decisão."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de dados de validação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma boa ideia usar um conjunto de validação. Esta é uma amostra dos dados que mantemos\n",
    "de volta de nossa análise e modelagem. Nós o usamos logo no final do nosso projeto para con rmar o\n",
    "precisão do nosso modelo nal. É um teste de fumaça que podemos usar para ver se erramos e nos dê confiança em nossas estimativas de precisão em dados não vistos. Usaremos 80% do conjunto de dados\n",
    "para modelagem e reter 20% para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n",
    "test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar algoritmos: linha de base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não temos ideia de quais algoritmos se sairão bem nesse problema. Intuição sugere regressão\n",
    "algoritmos como Linear Regression e ElasticNet podem funcionar bem. Também é possível que a decisão\n",
    "árvores e até SVM podem funcionar bem. Eu não faço ideia. Vamos projetar nosso equipamento de teste. Nós vamos usar\n",
    "Validação cruzada de 10 vezes. O conjunto de dados não é muito pequeno e este é um bom equipamento de teste padrão\n",
    "configuração. Avaliaremos algoritmos usando a métrica Mean Squared Error (MSE). MSE\n",
    "dará uma ideia grosseira de quão erradas estão todas as previsões (0 é perfeito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma linha de base de desempenho neste problema e verificar no local uma série de diferentes\n",
    "algoritmos. Vamos selecionar um conjunto de diferentes algoritmos capazes de trabalhar nesta regressão\n",
    "problema. Os seis algoritmos selecionados incluem:\n",
    "\n",
    ". Algoritmos Lineares: Regressão Linear (LR), Regressão Lasso (LASSO) e ElasticNet\n",
    "(PT).\n",
    ". Algoritmos Não Lineares: Árvores de Classificação e Regressão (CART), Vetor de Suporte\n",
    "Regressão (SVR) e k-vizinhos mais próximos (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os algoritmos usam parâmetros de ajuste padrão. Vamos comparar os algoritmos. Vamos\n",
    "exibir a média e o desvio padrão do MSE para cada algoritmo à medida que o calculamos e\n",
    "coletar os resultados para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que LR tem o MSE mais baixo, seguido de perto por CART."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada na distribuição de pontuações em todas as dobras de validação cruzada por algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver distribuições semelhantes para os algoritmos de regressão e talvez uma distribuição mais restrita de pontuações para CART."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As diferentes escalas dos dados provavelmente estão prejudicando a habilidade de todos os algoritmos e\n",
    "talvez mais ainda para SVR e KNN. Na próxima seção, veremos como executar o mesmo\n",
    "algoritmos usando uma cópia padronizada dos dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar algoritmos: padronização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspeitamos que as diferentes escalas dos dados brutos possam estar afetando negativamente a habilidade de\n",
    "alguns dos algoritmos. Vamos avaliar os mesmos algoritmos com uma cópia padronizada do\n",
    "conjunto de dados. É aqui que os dados são transformados de forma que cada atributo tenha um valor médio de\n",
    "zero e um desvio padrão de 1. Também precisamos evitar vazamento de dados quando transformamos o\n",
    "dados. Uma boa forma de evitar vazamentos é usar pipelines que padronizam os dados e constroem o\n",
    "modelo para cada dobra no chicote de teste de validação cruzada. Dessa forma, podemos obter uma estimativa justa\n",
    "de como cada modelo com dados padronizados pode funcionar em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',\n",
    "LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO',\n",
    "Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN',\n",
    "ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
    "KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
    "DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do exemplo fornece uma lista de erros quadráticos médios. Podemos ver que o escalonamento fez\n",
    "têm um efeito sobre o KNN, gerando um erro menor do que os outros modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada na distribuição das pontuações nas dobras de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que KNN tem uma distribuição restrita de erros e tem a pontuação mais baixa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melhore os resultados com o ajuste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos pelos resultados da seção anterior que KNN alcança bons resultados em escala\n",
    "versão do conjunto de dados. Mas pode fazer melhor. O valor padrão para o número de vizinhos em\n",
    "KNN é 7. Podemos usar uma pesquisa em grade para tentar um conjunto de diferentes números de vizinhos e ver se\n",
    "pode melhorar a pontuação. O exemplo abaixo tenta valores k ímpares de 1 a 21, um intervalo arbitrário\n",
    "cobrindo um bom valor conhecido de 7. Cada valor k (n vizinhos) é avaliado usando um cruzamento de 10 vezes\n",
    "validação em uma cópia padronizada do conjunto de dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "k_values = numpy.array([1,3,5,7,9,11,13,15,17,19,21])\n",
    "param_grid = dict(n_neighbors=k_values)\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos exibir as pontuações de média e desvio padrão, bem como o valor de melhor desempenho\n",
    "para k abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver que o melhor para k (n vizinhos) é 3, fornecendo um erro médio quadrado de\n",
    "-18.172137, o melhor até agora."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de conjunto( Ensemble )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra maneira de melhorar o desempenho dos algoritmos nesse problema é usando\n",
    "métodos de conjunto. Nesta seção, avaliaremos quatro métodos diferentes de aprendizado de máquina ensemble\n",
    "algoritmos, dois métodos boosting e dois bagging:\n",
    "\n",
    ". Métodos de Boosting: AdaBoost (AB) e Gradient Boosting (GBM).\n",
    ". Métodos de ensacamento: Random Forests (RF) e Extra Trees (ET).\n",
    "\n",
    "Usaremos o mesmo equipamento de teste de antes, validação cruzada de 10 vezes e pipelines que\n",
    "padronizar os dados de treinamento para cada dobra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB',\n",
    "AdaBoostRegressor())])))\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM',\n",
    "GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF',\n",
    "RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET',\n",
    "ExtraTreesRegressor())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do exemplo calcula o erro quadrático médio para cada método usando o padrão\n",
    "parâmetros. Podemos ver que geralmente estamos obtendo melhores pontuações do que nossos métodos lineares e não lineares\n",
    "algoritmos nas seções anteriores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos plotar a distribuição de pontuações nas dobras de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que o Gradient Boosting tem uma pontuação média melhor, também parece que Extra Trees tem uma\n",
    "distribuição semelhante e talvez uma pontuação mediana melhor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provavelmente podemos fazer melhor, visto que as técnicas de ensemble usaram os parâmetros padrão.\n",
    "Na próxima seção, veremos como ajustar o Gradient Boosting para aumentar ainda mais o desempenho."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O número padrão de estágios de reforço a serem executados (n estimadores) é 100. Essa é uma boa\n",
    "parâmetro candidato de Gradient Boosting para ajustar. Frequentemente, quanto maior o número de reforços\n",
    "estágios, melhor o desempenho, mas maior o tempo de treinamento. Nesta seção iremos\n",
    "veja como ajustar o número de estágios para aumentar o gradiente. Abaixo de nimos uma grade de parâmetros\n",
    "n valores de estimadores de 50 a 400 em incrementos de 50. Cada configuração é avaliada usando 10 vezes\n",
    "validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled GBM\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=numpy.array([50,100,150,200,250,300,350,400]))\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como antes, podemos resumir a melhor configuração e ter uma ideia de como o desempenho\n",
    "alterado a cada configuração diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a melhor configuração foi n estimadores = 400, resultando em uma média quadrada\n",
    "erro de -9,356471, cerca de 0,65 unidades melhor que o método desafinado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, podemos nalizar o modelo e prepará-lo para uso geral."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizar modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, vamos finalizar o modelo de aumento de gradiente e avaliá-lo em nosso teste\n",
    "conjunto de dados de validação. Primeiro, precisamos preparar o modelo e treiná-lo em todo o conjunto de dados de treinamento.\n",
    "Isso inclui padronizar o conjunto de dados de treinamento antes do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators=400)\n",
    "model.fit(rescaledX, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então dimensionar as entradas para o conjunto de dados de validação e gerar previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(mean_squared_error(Y_validation, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que o erro quadrático médio estimado é de 11,8, próximo de nossa estimativa de -9,3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
